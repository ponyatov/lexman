\secrel{Лексер и утилита \file{flex}}\label{lexer}\secdown

\termdef{лексер}{Лексер}\ выполняет разбор входного потока единичных символов,
выделяя из него группы символов. Код лексера генерируется с помощью утилиты
\prog{flex}, из набора правил, состоящих из двух частей:

\begin{enumerate}
\item регулярное выражение \ref{regexp}, задающее шаблон для выделения группы 
символов, и
\item блок произвольного кода на \cpp, выполняющего с найденным текстом нужные
действия.
\end{enumerate}

Для простых применений вы можете прописать нужные вам действия непосредственно
с заданным текстом (запись в отдельный файл, преобразования,\ldots).

\begin{framed}
В случае использования лексера в составе транслятора/комипилятора, лексер
выполняет \termdef{токенизация}{токенизацию}: первичное преобразование 
найденных блоков исходного текста в \term{токены}.
\end{framed} 

\secrel{Структура файла описания лексера}

Для утилиты \prog{flex}\note{или ее предшественника \prog{lex}} используется
файл с расширением \verb|.l|/\verb|.lex|/\verb|.lpp|\ \cite{openlex}:

\begin{verbatim}
// секция определений
    %{
        // заголовочный C++ код
        #include "hpp.hpp"
        #include "parser.tab.hpp"
        std::string StringParseBuffer;
    %}
    // опции
        %option ...
    // дополнительные состояния лексера
        %x state1
        %s state2
// секция правил
    %%
    %%
// секция подпрограмм
\end{verbatim}

Минимальный вариант .lex-файла:

\begin{verbatim}
%option main    // добавить автоматическую функцию main() 
%%
...    // правила
\n     {<код для конца строки>} или {}
.      {<код для нераспознанного символа>}, {}
%%
\end{verbatim}

\secrel{Запуск \prog{flex}}\secdown

\secrel{Запуск в варианте для старого \prog{lex}}

Для начала рассмотрим вариант использования для старой версии
лексического генератора \prog{lex}, который вы внезапно встретите
в какой-нибудь старой коммерческой UNIX-системе. Подробно отличия 
рассмотрены в \cite{lextoflex}.

\lstx{empty.l}{empty.l}

\begin{verbatim}
lex empty.l
cc -o -o empty.exe lex.yy.c
./empty.exe < lex.yy.c > empty.log 
\end{verbatim}

После выполнения команды \verb|lex|\ будет создан 
файл \verb|lex.yy.c|, содержащий \emph{чисто сишный}\ код лексера, 
\emph{который можно откомпилировать любым ANSI-совместимым компилятором Си
для любого микроконтроллера}, или отечественной ВПКшной поделки типа 
\href{http://www.angstrem.ru/products/micro/tesey-8/KP1878BE1.html}{КР1878ВЕ1}.
Для проверки своих программ можете использовать
\verb|cc = gcc -std=c89 -Wpedantic|.

Полученная программа читает символы с \verb|stdin|, и выводит все 
нераспознанные символы на \verb|stdout|.

\secup

\input{regexp}

\secrel{Примеры самостоятельного применения}\secdown

\begin{framed}
\noindent Лексер может быть использован как самостоятельный инструмент, если
не требуется анализ синтаксиса, и достаточно выполнять заданный \cpp\ код
при срабатывании одного из регулярных выражений.
\end{framed}

\secrel{\file{Pij2D}: загрузка файла числовых данных}

Формат файла: \bigskip

\begin{itemize}[nosep]
\item число строк матрицы max=Rmax
\item число элементов в строке max=Xmax
\item данные построчно
\end{itemize}

\lstx{Fi.dat}{tmp/Fi.dat}
\lstx{Pij2D.lpp}{../pij/pij2d/lpp.lpp}
\lst{hpp.hpp}{../pij/pij2d/hpp.hpp}{c++}
\lst{cpp.cpp}{tmp/pij.main}{c++}

\begin{verbatim}
Rmax 					// строк, не более чем 
Xmax 					// столбцов, не более чем
double Fi[Rmax][Xmax]	// массив под данные
int item				// общий счетчик прочитанных чисел

argc, argv				// часть исходных данных задается с командной строки
doit()					// функция обработки данных

while (yylex());		// цикл опроса лексера,
yylex()					// на каждый вызов возвращается один токен
\end{verbatim}

\verb|item|\ используется для определения, какой тип имеет текущее 
прочитанное число: \verb|Rlimit|, \verb|Xlimit| или данные.

Конец строки в обработке не участвует, факт перехода на следующую строку
матрицы определяется по превышению Xlimit.

\secup
\secup
